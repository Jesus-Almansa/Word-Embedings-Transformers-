{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktFg2jj3jTE6"
   },
   "source": [
    "# ACTIVIDAD DE CLASIFICACIÓN DE TEXTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZ-OuW5DiLJs"
   },
   "source": [
    "En esta actividad vamos a trabajar en clasificar textos. Se recorrerá todo el proceso desde traer el dataset hasta proceder a dicha clasificación. Durante la actividad se llevarán a cabo muchos procesos como la creación de un vocabulario, el uso de embeddings y la creación de modelos.\n",
    "\n",
    "Las cuestiones presentes en esta actividad están basadas en un Notebook creado por François Chollet, uno de los creadores de Keras y autor del libro \"Deep Learning with Python\". \n",
    "\n",
    "En este Notebook se trabaja con el dataset \"Newsgroup20\" que contiene aproximadamente 20000 mensajes que pertenecen a 20 categorías diferentes.\n",
    "\n",
    "El objetivo es entender los conceptos que se trabajan y ser capaz de hacer pequeñas experimentaciones para mejorar el Notebook creado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hytURWLLjZvT"
   },
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DbxRuvOwkzSs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXfYbCflkQYy"
   },
   "source": [
    "# Descarga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e-1ZhOf3lB_A"
   },
   "outputs": [],
   "source": [
    "data_path = keras.utils.get_file(\n",
    "    \"news20.tar.gz\",\n",
    "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n",
    "    untar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3ygvoWhlCYj",
    "outputId": "e8fcf46c-12fc-4bc3-d112-b273633b4415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of directories: 20\n",
      "Directory names: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "#Estructura de directorios del dataset\n",
    "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n",
    "dirnames = os.listdir(data_dir)\n",
    "print(\"Number of directories:\", len(dirnames))\n",
    "print(\"Directory names:\", dirnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Del Cerro Recuero\\.keras\\datasets\\20_newsgroup\n"
     ]
    }
   ],
   "source": [
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OG8rjgOFlcaV",
    "outputId": "8ba4fa96-0058-41c9-ed63-5532b7ac04cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in comp.graphics: 1000\n",
      "Some example filenames: ['37261', '37913', '37914', '37915', '37916']\n"
     ]
    }
   ],
   "source": [
    "#Algunos archivos de la categoria \"com.graphics\"\n",
    "fnames = os.listdir(data_dir / \"comp.graphics\")\n",
    "print(\"Number of files in comp.graphics:\", len(fnames))\n",
    "print(\"Some example filenames:\", fnames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ox6s6z9lgps",
    "outputId": "c7a40ef1-6212-481e-e822-a3570f1c6837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: cantaloupe.srv.cs.cmu.edu!rochester!udel!gatech!howland.reston.ans.net!newsserver.jvnc.net!castor.hahnemann.edu!hal.hahnemann.edu!brennan\n",
      "From: brennan@hal.hahnemann.edu\n",
      "Newsgroups: comp.graphics\n",
      "Subject: .GIFs on a Tek401x ??\n",
      "Date: 15 MAY 93 14:29:54 EST\n",
      "Organization: Hahnemann University\n",
      "Lines: 14\n",
      "Message-ID: <15MAY93.14295461@hal.hahnemann.edu>\n",
      "NNTP-Posting-Host: hal.hahnemann.edu\n",
      "\n",
      "\n",
      "      I was skimming through a few gophers and bumped into one at NIH\n",
      "   with a database that included images in .GIF format.  While I have\n",
      "   not yet worked out the kinks of getting the gopher client to call\n",
      "   an X viewer, I figure that the majority of the users here are not\n",
      "   in an X11 environment - instead using DOS and MS-Kermit.\n",
      "\n",
      "      With Kermit supporting Tek4010 emulation for graphics display,\n",
      "   does anyone know of a package that would allow a Tek to display a\n",
      "   .GIF image?  It would be of more use to the local population to\n",
      "   plug something of this sort in as the 'picture' command instead of\n",
      "   XView or XLoadImage ...\n",
      "\n",
      "      andrew.  (brennan@hal.hahnemann.edu)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ejemplo de un texto de la categoría \"com.graphics\"\n",
    "print(open(data_dir / \"comp.graphics\" / \"39625\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vUbbjI8plaG0",
    "outputId": "c538adab-845e-42d5-a091-8e6403e77889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in talk.politics.misc: 1000\n",
      "Some example filenames: ['124146', '176845', '176846', '176847', '176849']\n"
     ]
    }
   ],
   "source": [
    "#Algunos archivos de la categoria \"talk.politics.misc\"\n",
    "fnames = os.listdir(data_dir / \"talk.politics.misc\")\n",
    "print(\"Number of files in talk.politics.misc:\", len(fnames))\n",
    "print(\"Some example filenames:\", fnames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izZGWhpklCbI",
    "outputId": "a9483dfd-8d78-46bd-863e-c7d992b645d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xref: cantaloupe.srv.cs.cmu.edu talk.politics.guns:54219 talk.politics.misc:178463\n",
      "Newsgroups: talk.politics.guns,talk.politics.misc\n",
      "Path: cantaloupe.srv.cs.cmu.edu!magnesium.club.cc.cmu.edu!news.sei.cmu.edu!cis.ohio-state.edu!magnus.acs.ohio-state.edu!usenet.ins.cwru.edu!agate!spool.mu.edu!darwin.sura.net!martha.utcc.utk.edu!FRANKENSTEIN.CE.UTK.EDU!VEAL\n",
      "From: VEAL@utkvm1.utk.edu (David Veal)\n",
      "Subject: Re: Proof of the Viability of Gun Control\n",
      "Message-ID: <VEAL.749.735192116@utkvm1.utk.edu>\n",
      "Lines: 21\n",
      "Sender: usenet@martha.utcc.utk.edu (USENET News System)\n",
      "Organization: University of Tennessee Division of Continuing Education\n",
      "References: <1qpbqd$ntl@access.digex.net> <C5otvp.ItL@magpie.linknet.com>\n",
      "Date: Mon, 19 Apr 1993 04:01:56 GMT\n",
      "\n",
      "[alt.drugs and alt.conspiracy removed from newsgroups line.]\n",
      "\n",
      "In article <C5otvp.ItL@magpie.linknet.com> neal@magpie.linknet.com (Neal) writes:\n",
      "\n",
      ">   Once the National Guard has been called into federal service,\n",
      ">it is under the command of the present. Tha National Guard, though\n",
      ">defined as the \"Militia\" in the statutes, is actually a reserve component\n",
      ">of the United State Army, and was formed pursuant to the power of Congress\n",
      ">to raise and support Armies.\n",
      "\n",
      "       That's the really cute thing about saying the 2nd amendment\n",
      "only covers the national guard, because that would mean that it\n",
      "essentially prohibits the federal government from disarming a branch\n",
      "of the federal government.\n",
      "\n",
      "       Sounds like a real limit to federal power to me.\n",
      "------------------------------------------------------------------------\n",
      "David Veal Univ. of Tenn. Div. of Cont. Education Info. Services Group\n",
      "PA146008@utkvm1.utk.edu - \"I still remember the way you laughed, the day\n",
      "your pushed me down the elevator shaft;  I'm beginning to think you don't\n",
      "love me anymore.\" - \"Weird Al\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ejemplo de un texto de la categoría \"talk.politics.misc\"\n",
    "print(open(data_dir / \"talk.politics.misc\" / \"178463\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33Ay5U6blCd1",
    "outputId": "497818bb-b7b7-4506-967b-c119287a7412"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing alt.atheism, 1000 files found\n",
      "Processing comp.graphics, 1000 files found\n",
      "Processing comp.os.ms-windows.misc, 1000 files found\n",
      "Processing comp.sys.ibm.pc.hardware, 1000 files found\n",
      "Processing comp.sys.mac.hardware, 1000 files found\n",
      "Processing comp.windows.x, 1000 files found\n",
      "Processing misc.forsale, 1000 files found\n",
      "Processing rec.autos, 1000 files found\n",
      "Processing rec.motorcycles, 1000 files found\n",
      "Processing rec.sport.baseball, 1000 files found\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[0;32m     11\u001b[0m     fpath \u001b[38;5;241m=\u001b[39m dirpath \u001b[38;5;241m/\u001b[39m fname\n\u001b[1;32m---> 12\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(fpath, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m     content \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     14\u001b[0m     lines \u001b[38;5;241m=\u001b[39m content\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "labels = []\n",
    "class_names = []\n",
    "class_index = 0\n",
    "for dirname in sorted(os.listdir(data_dir)):\n",
    "    class_names.append(dirname)\n",
    "    dirpath = data_dir / dirname\n",
    "    fnames = os.listdir(dirpath)\n",
    "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
    "    for fname in fnames:\n",
    "        fpath = dirpath / fname\n",
    "        f = open(fpath, encoding=\"latin-1\")\n",
    "        content = f.read()\n",
    "        lines = content.split(\"\\n\")\n",
    "        lines = lines[10:]\n",
    "        content = \"\\n\".join(lines)\n",
    "        samples.append(content)\n",
    "        labels.append(class_index)\n",
    "    class_index += 1\n",
    "\n",
    "print(\"Classes:\", class_names)\n",
    "print(\"Number of samples:\", len(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2pmvE6gMcxT"
   },
   "source": [
    "# Mezclando los datos para separarlos en Traning y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DYX7x-k_lCgZ"
   },
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "seed = 1337\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(samples)\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(labels)\n",
    "\n",
    "# Extract a training & validation split\n",
    "validation_split = 0.2\n",
    "num_validation_samples = int(validation_split * len(samples))\n",
    "train_samples = samples[:-num_validation_samples]\n",
    "val_samples = samples[-num_validation_samples:]\n",
    "train_labels = labels[:-num_validation_samples]\n",
    "val_labels = labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IktOtKfpNx8E"
   },
   "source": [
    "# Tokenización de las palabras con TextVectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QjHgQPX8lCjO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vIWC37s5smZ4",
    "outputId": "8ff450dd-7dc8-466b-cb7f-5d53e8834f42"
   },
   "outputs": [],
   "source": [
    "vectorizer.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vit8TPqTvmwS",
    "outputId": "fe7fb758-3b10-41c1-a45e-5d332fa75acb"
   },
   "outputs": [],
   "source": [
    "len(vectorizer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2O-FXA9wPVkg"
   },
   "source": [
    "# Viendo la salida de Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rseIF0fLmyJ0",
    "outputId": "a368a7e9-da0f-4a79-a7e5-33488951680c"
   },
   "outputs": [],
   "source": [
    "output = vectorizer([[\"the cat sat on the mat\"]])\n",
    "output.numpy()[0, :6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wsr4AQtBFArV",
    "outputId": "09267722-32fe-4833-cd2d-65c67938e3a7"
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SL5ag8UamzwL"
   },
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08v8SKcsn3lf",
    "outputId": "0e9272d0-bec1-4326-90fe-4daea19f7f65"
   },
   "outputs": [],
   "source": [
    "test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
    "[word_index[w] for w in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eBhadrvOTNZ"
   },
   "source": [
    "# Tokenización de los datos de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W26LUr2dKTOj"
   },
   "outputs": [],
   "source": [
    "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
    "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3QVIb84Olda"
   },
   "source": [
    "# Creación y entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9VxI-i69cdB"
   },
   "outputs": [],
   "source": [
    "# pon aquí tu código\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Creación del modelo\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(vectorizer.get_vocabulary()), output_dim=64, input_length=200))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(class_names), activation='softmax'))\n",
    "\n",
    "# Compilación del modelo\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=30,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_val, y_val))\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\tUtilizando el tokenizador de spacy, que ya conoces, calcula el número promedio de tokens de una muestra de 15 ficheros de la categoría ‘com.graphics’. Indica el código utilizado y el resultado obtenido. (1 punto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import glob\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "directory_path = 'C:/Users/Del Cerro Recuero/.keras/datasets/20_newsgroup/comp.graphics/*'\n",
    "\n",
    "#obtenemos  lista de archivos que coinciden con el patrón dado. \n",
    "sample_files = glob.glob(directory_path)[:15]\n",
    "\n",
    "total_tokens = 0\n",
    "num_files = 0\n",
    "\n",
    "for file in sample_files:\n",
    "    if os.path.isfile(file) and os.path.splitext(file)[1] == '':\n",
    "#Abrimos el archivo, leemos su contenido, y pasamos al modelo de spaCy para obtener el documento procesado y actualizamos los contadores de tokens y archivos.\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            doc = nlp(text)\n",
    "            total_tokens += len(doc)\n",
    "            num_files += 1\n",
    "\n",
    "#Calculamos el número promedio de tokens dividiendo el conteo total de tokens entre el número de archivos procesados.\n",
    "average_tokens = total_tokens / num_files\n",
    "\n",
    "print(\"Número promedio de tokens:\", average_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\tEl código proporcionado lee los ficheros uno a uno y, antes de generar el catálogo de datos de entrenamiento y validación, descarta las 10 primeras líneas de cada fichero. ¿Cuál es el trozo de código en el que se realiza dicho descarte?, ¿por qué crees que se descartan dichas líneas?, ¿por qué 10 y no otro número? (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro del bluque 'for fname in fname' y es el siguiente: \n",
    "lines = content.split(\"\\n\")   \n",
    "        lines = lines[10:]   \n",
    "        content = \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El motivo por la que se descartan las primeras 10 líneas es porque, en este caso, se considera que esas líneas contienen información adicional o metadatos que no son relevantes para el análisis o encabezados del texto. Al eliminar estas líneas, se obtiene un conjunto de datos más limpio y enfocado en el contenido principal de los ficheros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al elegir más de 10 diez lineas se eliminaria información levelante para el objeto del analisis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\t¿Qué se controla con el parámetro 'validation_split'?, ¿por qué se ha elegido ese valor?, ¿qué ocurre si lo modificas? (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro 'validation_split' controla el tamaño del conjunto de datos que se utilizará como datos de validación durante el entrenamiento del modelo. Este parámetro indica el  porcentaje de los datos se separará para su uso en la validación, mientras que el resto se utilizará para el entrenamiento.\n",
    "\n",
    "En el código, se ha indicado el valor de 'validation_split' en 0.2, lo que significa que el 20% de los datos se utilizará como conjunto de validación. Esta elección se basa en la buenas practicas empleadas en este modelos. \n",
    "\n",
    "Si se modifica el valor de 'validation_split' a un número diferente, cambiamos la proporción de datos que se utilizarán para la validación. Por ejemplo, si se establece en 0.3, se utilizará el 30% de los datos para la validación, dejando el 70% restante para el entrenamiento. Ajustar este valor puede afectar el rendimiento del modelo y su capacidad para generalizar a nuevos datos. Elegir un valor adecuado para 'validation_split' depende del tamaño del conjunto de datos, la cantidad de datos disponibles y las características específicas de los datos. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\tImprime por pantalla un ejemplo (es decir, un elemento del array) de ‘train_samples’, ‘val_samples’, ‘train_labels’ y ‘val_labels’. A tenor de las etiquetas que se utilizan, ¿qué tarea crees que se está intentando entrenar? (1 punto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ejemplo de train_samples:\", train_samples[0])\n",
    "print(\"Ejemplo de val_samples:\", val_samples[0])\n",
    "print(\"Ejemplo de train_labels:\", train_labels[0])\n",
    "print(\"Ejemplo de val_labels:\", val_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La tarea que se esté intentando entrenar es una tarea de clasificación de texto. Las etiquetas representan las categorías o clases a las que pertenecen los datos. Por ejemplo: computer graphic, alt.atheism, comp.sys.mac.hardware.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\tCon 'output_sequence_length' se establece un tamaño fijo para la salida de Vectorizer. ¿Por qué se necesita un tamaño fijo, y por qué se ha elegido el valor ‘200’? (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es necesario establecer un tamaño fijo para poder procesar los datos en lotes de manera optima y para garantizar la consistencia en las dimensiones de entrada del modelo. \n",
    "\n",
    "¿Por qué se ha elegido el valor ‘200’?,el porque de un tamaño fijo es para busca limitar la longitud de las secuencias del texto a un tamaño manejable y representativo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.\tIndica cuál es la precisión del modelo en el conjunto de datos de entrenamiento y en el conjunto de datos de validación. ¿Qué interpretación puedes dar? Haz en este punto un análisis comparativo de los dos modelos ejecutados. (1.5 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el modelo basado en Transformers, la precisión en el conjunto de datos de entrenamiento es de aproximadamente 93.91% después de 20 épocas, mientras que la precisión en el conjunto de datos de validación es de aproximadamente 79.74%. Esto significa que el modelo tiene un buen rendimiento en el conjunto de datos de entrenamiento, alcanzando una alta precisión, pero hay cierta discrepancia en el conjunto de datos de validación, lo que indica que el modelo puede estar sobre ajustando los datos de entrenamiento y no generalizando tan bien a nuevos datos.\n",
    "\n",
    "Por otro lado, en el modelo de Red Neuronal Clásica, la precisión en el conjunto de datos de entrenamiento es de aproximadamente 96.58% después de 20 épocas, mientras que la precisión en el conjunto de datos de validación es de aproximadamente 71.57%. Aquí también se observa una discrepancia entre la precisión en el conjunto de entrenamiento y el de validación, lo que sugiere que el modelo puede estar sobre ajustando los datos de entrenamiento y no generalizando adecuadamente.\n",
    "\n",
    "En comparación, el modelo basado en Transformers tiene una precisión ligeramente mayor tanto en el conjunto  de validación en comparación con el modelo de Red Neuronal Clásica. Sin embargo, ambos modelos presentan cierto grado de sobreajuste, lo que puede ser abordado mediante técnicas como regularización y aumento de datos para mejorar la generalización del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.\tEn la parte final del código se hace un análisis cualitativo de la salida. Explica el funcionamiento de este análisis e interpreta los resultados. Haz también en este punto un análisis comparativo de los dos modelos ejecutados. (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red Neuronal Clásica: El primero comenta sobre tarjeta grafica y lo acierta indicando: comp.graphics\n",
    "en cambio cuando habla de politica no lo acierta indicando: alt.atheismo y la tercera evaluacio tampoco lo acierta porque habla \n",
    "de religion y presenta comp.sys.mac.hardware. \n",
    "\n",
    "En el modelo basado en Transforml: El  primero si que lo acierta, el segundo parece que tambien lo acierta, pero la palabra \"guns\" no sabemos como la obtiene y la tercera si parece que esta hablando de religion, pero la palabra \"alt\" no sabemos el significado y ni el contexto. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.\tExplica algunas de las limitaciones que puedes encontrar al modelo entrenado. (1.5 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A contoninuacion explicamos algunas limitaciones de este tipos de modelos.\n",
    "\n",
    "    Ironia: Para un modelo puede ser complicado dectectar sarcasmo o ironia. En este caso son caracteristica del ser humano. \n",
    "    \n",
    "    Idioma: Es necesario mantener actualizado el modelo  por que el idioma puede sufrir modidificaciones.\n",
    "    \n",
    "    Sesgo de datos: Si los datos de entrenamiento están sesgados hacia ciertas clases, el modelo puede tener dificultades para generalizar correctamente a clases menos representadas, lo que resulta en una precisión más baja para esas clases.\n",
    "\n",
    "    Tamaño del conjunto de datos: El rendimiento del modelo puede verse afectado por el tamaño del conjunto de datos utilizado para entrenar. Si el conjunto de datos es pequeño, el modelo puede tener dificultades para aprender patrones generales y puede sufrir de sobreajuste, lo que significa que se adapta demasiado a los datos de entrenamiento y no generaliza bien a nuevos datos.\n",
    "\n",
    "    Composición del texto: Dependiendo del tipo de texto que se está clasificando, pueden existir desafíos adicionales, como errores ortográficos, jerga o ambigüedad. Estos factores pueden dificultar la interpretación precisa del significado del texto por parte del modelo y afectar sus predicciones.\n",
    "\n",
    "    Representación de palabras: El modelo utiliza embeddings para representar las palabras como vectores. La calidad de los embeddings y la representación de las palabras pueden afectar el rendimiento del modelo. Si las palabras clave relevantes no están bien capturadas en los vectores de embedding o si hay mucha variabilidad en las representaciones de palabras similares, el modelo puede tener dificultades para aprender las relaciones semánticas entre las palabras.\n",
    "\n",
    "    Arquitectura del modelo: El modelo actual tiene una arquitectura relativamente simple con una capa de embedding, una capa de promedio global y dos capas densas. Esta arquitectura puede ser adecuada para algunos problemas, pero para problemas más complejos, puede ser necesario explorar arquitecturas más avanzadas, como redes neuronales recurrentes (RNN), redes neuronales convolucionales (CNN) o modelos basados en atención."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obtener la frecuencia de cada clase\n",
    "class_frequencies = {}\n",
    "for label in labels:\n",
    "    if label in class_frequencies:\n",
    "        class_frequencies[label] += 1\n",
    "    else:\n",
    "        class_frequencies[label] = 1\n",
    "\n",
    "# Calcular el porcentaje de cada clase\n",
    "total_instances = len(labels)\n",
    "class_percentages = {label: freq / total_instances for label, freq in class_frequencies.items()}\n",
    "\n",
    "# Visualizar la distribución de clases\n",
    "labels = class_percentages.keys()\n",
    "frequencies = class_percentages.values()\n",
    "\n",
    "plt.bar(labels, frequencies)\n",
    "plt.xlabel('Clases')\n",
    "plt.ylabel('Porcentaje')\n",
    "plt.title('Distribución de Clases')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.\t¿Qué sería necesario para que este modelo pueda interpretar textos en español? (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para permitir que el modelo interprete textos en español, es necesario seguir algunos pasos adicionales. Primero, se requiere un conjunto de datos etiquetados en español que contenga ejemplos de textos y sus respectivas etiquetas.\n",
    "\n",
    "Además, sera necesario adaptar el preprocesamiento del texto para lidiar con las particularidades del español, como caracteres especiales, puntuación, acentos y otros aspectos específicos del idioma.\n",
    "\n",
    "Para trabajar con textos en español, se necesitarán embeddings específicos del idioma. Estos embeddings son representaciones vectoriales de palabras que capturan su significado semántico. Puedes utilizar embeddings pre-entrenados en español, como FastText o Word2Vec, o entrenar tus propios embeddings en un corpus de texto en español.\n",
    "\n",
    "Para evaluar el rendimiento del modelo, es necesario contar con etiquetas y datos de prueba en español. Esto implica traducir o recolectar datos etiquetados en español que representen las clases o categorías que deseas predecir.\n",
    "\n",
    "Una vez que reunido todos los elementos que acabmos de destacar, se debera adaptar el código y realizar el entrenamiento del modelo utilizando el conjunto de datos en español, los embeddings y los modelos de lenguaje correspondientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4x_4eXJVrnX"
   },
   "source": [
    "# Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "fgg7KnoioNYc",
    "outputId": "78d936fe-0c57-461b-9355-0cd2774e7726"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "x = vectorizer(string_input)\n",
    "preds = modeloEmbeddingGloveTransformers(x)\n",
    "end_to_end_model = keras.Model(string_input, preds)\n",
    "\n",
    "probabilities = end_to_end_model.predict(\n",
    "    [[\"this message is about computer graphics and 3D modeling\"]]\n",
    ")\n",
    "\n",
    "class_names[np.argmax(probabilities[0])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Carga el modelo previamente guardado\n",
    "modeloEmbeddingGloveTransformers = load_model('ruta_del_modelo/modelo.h5')\n",
    "\n",
    "# Continúa con el resto del código\n",
    "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "x = vectorizer(string_input)\n",
    "preds = modeloEmbeddingGloveTransformers(x)\n",
    "end_to_end_model = keras.Model(string_input, preds)\n",
    "\n",
    "probabilities = end_to_end_model.predict(\n",
    "    [[\"this message is about computer graphics and 3D modeling\"]]\n",
    ")\n",
    "\n",
    "class_names[np.argmax(probabilities[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "R-EXfK6qoSAd",
    "outputId": "f3060f75-8ed6-4eb3-aaad-e9d18b80ab9a"
   },
   "outputs": [],
   "source": [
    "probabilities = end_to_end_model.predict(\n",
    "    [[\"politics and federal courts law that people understand with politician and elects congressman\"]]\n",
    ")\n",
    "\n",
    "class_names[np.argmax(probabilities[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "QByfYDv4rGqv",
    "outputId": "a139439d-56e4-447b-baa6-7b2a6be53c08"
   },
   "outputs": [],
   "source": [
    "probabilities = end_to_end_model.predict(\n",
    "    [[\"we are talking about religion\"]]\n",
    ")\n",
    "\n",
    "class_names[np.argmax(probabilities[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
